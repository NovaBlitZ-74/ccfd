{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f97d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205ebcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b661cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical info\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e1d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# datatype info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3058e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f058475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_17872\\2366297431.py:3: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(df['Class']).plot.bar()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Exploratory Data Analysis\n",
    "\n",
    "pd.value_counts(df['Class']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75820dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.173963e-01</td>\n",
       "      <td>-1.059333e-02</td>\n",
       "      <td>-4.196182e-01</td>\n",
       "      <td>-1.052602e-01</td>\n",
       "      <td>1.730721e-01</td>\n",
       "      <td>-6.301647e-02</td>\n",
       "      <td>8.471437e-02</td>\n",
       "      <td>-3.694943e-02</td>\n",
       "      <td>-8.660434e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.473573e-02</td>\n",
       "      <td>1.440591e-01</td>\n",
       "      <td>5.114236e-02</td>\n",
       "      <td>-1.618187e-02</td>\n",
       "      <td>-2.330828e-01</td>\n",
       "      <td>-4.140710e-02</td>\n",
       "      <td>-5.134591e-03</td>\n",
       "      <td>-9.412688e-03</td>\n",
       "      <td>-0.010596</td>\n",
       "      <td>-0.012323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.117396</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.135835e-16</td>\n",
       "      <td>-1.227819e-15</td>\n",
       "      <td>-9.215150e-16</td>\n",
       "      <td>1.812612e-17</td>\n",
       "      <td>-6.506567e-16</td>\n",
       "      <td>-1.005191e-15</td>\n",
       "      <td>-2.433822e-16</td>\n",
       "      <td>-1.513678e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.457409e-16</td>\n",
       "      <td>-4.290944e-16</td>\n",
       "      <td>6.168652e-16</td>\n",
       "      <td>-4.425156e-17</td>\n",
       "      <td>-9.605737e-16</td>\n",
       "      <td>-1.581290e-17</td>\n",
       "      <td>1.198124e-16</td>\n",
       "      <td>2.083082e-15</td>\n",
       "      <td>-0.227709</td>\n",
       "      <td>-0.101347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.010593</td>\n",
       "      <td>4.135835e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.243764e-16</td>\n",
       "      <td>-1.121065e-15</td>\n",
       "      <td>5.157519e-16</td>\n",
       "      <td>2.787346e-16</td>\n",
       "      <td>2.055934e-16</td>\n",
       "      <td>-5.377041e-17</td>\n",
       "      <td>1.978488e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.480447e-17</td>\n",
       "      <td>1.526333e-16</td>\n",
       "      <td>1.634231e-16</td>\n",
       "      <td>1.247925e-17</td>\n",
       "      <td>-4.478846e-16</td>\n",
       "      <td>2.057310e-16</td>\n",
       "      <td>-4.966953e-16</td>\n",
       "      <td>-5.093836e-16</td>\n",
       "      <td>-0.531409</td>\n",
       "      <td>0.091289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.419618</td>\n",
       "      <td>-1.227819e-15</td>\n",
       "      <td>3.243764e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.711293e-16</td>\n",
       "      <td>-6.539009e-17</td>\n",
       "      <td>1.627627e-15</td>\n",
       "      <td>4.895305e-16</td>\n",
       "      <td>-1.268779e-15</td>\n",
       "      <td>5.568367e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>5.706192e-17</td>\n",
       "      <td>-1.133902e-15</td>\n",
       "      <td>-4.983035e-16</td>\n",
       "      <td>2.686834e-19</td>\n",
       "      <td>-1.104734e-15</td>\n",
       "      <td>-1.238062e-16</td>\n",
       "      <td>1.045747e-15</td>\n",
       "      <td>9.775546e-16</td>\n",
       "      <td>-0.210880</td>\n",
       "      <td>-0.192961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.105260</td>\n",
       "      <td>-9.215150e-16</td>\n",
       "      <td>-1.121065e-15</td>\n",
       "      <td>4.711293e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.719944e-15</td>\n",
       "      <td>-7.491959e-16</td>\n",
       "      <td>-4.104503e-16</td>\n",
       "      <td>5.697192e-16</td>\n",
       "      <td>6.923247e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.949553e-16</td>\n",
       "      <td>-6.276051e-17</td>\n",
       "      <td>9.164206e-17</td>\n",
       "      <td>1.584638e-16</td>\n",
       "      <td>6.070716e-16</td>\n",
       "      <td>-4.247268e-16</td>\n",
       "      <td>3.977061e-17</td>\n",
       "      <td>-2.761403e-18</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.133447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.173072</td>\n",
       "      <td>1.812612e-17</td>\n",
       "      <td>5.157519e-16</td>\n",
       "      <td>-6.539009e-17</td>\n",
       "      <td>-1.719944e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408382e-16</td>\n",
       "      <td>2.715541e-16</td>\n",
       "      <td>7.437229e-16</td>\n",
       "      <td>7.391702e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.920976e-16</td>\n",
       "      <td>1.253751e-16</td>\n",
       "      <td>-8.428683e-18</td>\n",
       "      <td>-1.149255e-15</td>\n",
       "      <td>4.808532e-16</td>\n",
       "      <td>4.319541e-16</td>\n",
       "      <td>6.590482e-16</td>\n",
       "      <td>-5.613951e-18</td>\n",
       "      <td>-0.386356</td>\n",
       "      <td>-0.094974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-0.063016</td>\n",
       "      <td>-6.506567e-16</td>\n",
       "      <td>2.787346e-16</td>\n",
       "      <td>1.627627e-15</td>\n",
       "      <td>-7.491959e-16</td>\n",
       "      <td>2.408382e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.191668e-16</td>\n",
       "      <td>-1.104219e-16</td>\n",
       "      <td>4.131207e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>5.833316e-17</td>\n",
       "      <td>-4.705235e-19</td>\n",
       "      <td>1.046712e-16</td>\n",
       "      <td>-1.071589e-15</td>\n",
       "      <td>4.562861e-16</td>\n",
       "      <td>-1.357067e-16</td>\n",
       "      <td>-4.452461e-16</td>\n",
       "      <td>2.594754e-16</td>\n",
       "      <td>0.215981</td>\n",
       "      <td>-0.043643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.084714</td>\n",
       "      <td>-1.005191e-15</td>\n",
       "      <td>2.055934e-16</td>\n",
       "      <td>4.895305e-16</td>\n",
       "      <td>-4.104503e-16</td>\n",
       "      <td>2.715541e-16</td>\n",
       "      <td>1.191668e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.344412e-16</td>\n",
       "      <td>1.122501e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.027779e-16</td>\n",
       "      <td>-8.898922e-16</td>\n",
       "      <td>-4.387401e-16</td>\n",
       "      <td>7.434913e-18</td>\n",
       "      <td>-3.094082e-16</td>\n",
       "      <td>-9.657637e-16</td>\n",
       "      <td>-1.782106e-15</td>\n",
       "      <td>-2.776530e-16</td>\n",
       "      <td>0.397311</td>\n",
       "      <td>-0.187257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.036949</td>\n",
       "      <td>-2.433822e-16</td>\n",
       "      <td>-5.377041e-17</td>\n",
       "      <td>-1.268779e-15</td>\n",
       "      <td>5.697192e-16</td>\n",
       "      <td>7.437229e-16</td>\n",
       "      <td>-1.104219e-16</td>\n",
       "      <td>3.344412e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.356078e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.892798e-16</td>\n",
       "      <td>2.026927e-16</td>\n",
       "      <td>6.377260e-17</td>\n",
       "      <td>-1.047097e-16</td>\n",
       "      <td>-4.653279e-16</td>\n",
       "      <td>-1.727276e-16</td>\n",
       "      <td>1.299943e-16</td>\n",
       "      <td>-6.200930e-16</td>\n",
       "      <td>-0.103079</td>\n",
       "      <td>0.019875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>-0.008660</td>\n",
       "      <td>-1.513678e-16</td>\n",
       "      <td>1.978488e-17</td>\n",
       "      <td>5.568367e-16</td>\n",
       "      <td>6.923247e-16</td>\n",
       "      <td>7.391702e-16</td>\n",
       "      <td>4.131207e-16</td>\n",
       "      <td>1.122501e-15</td>\n",
       "      <td>4.356078e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.936953e-16</td>\n",
       "      <td>-7.071869e-16</td>\n",
       "      <td>-5.214137e-16</td>\n",
       "      <td>-1.430343e-16</td>\n",
       "      <td>6.757763e-16</td>\n",
       "      <td>-7.888853e-16</td>\n",
       "      <td>-6.709655e-17</td>\n",
       "      <td>1.110541e-15</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>-0.097733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.030617</td>\n",
       "      <td>7.388135e-17</td>\n",
       "      <td>-3.991394e-16</td>\n",
       "      <td>1.156587e-15</td>\n",
       "      <td>2.232685e-16</td>\n",
       "      <td>-5.202306e-16</td>\n",
       "      <td>5.932243e-17</td>\n",
       "      <td>-7.492834e-17</td>\n",
       "      <td>-2.801370e-16</td>\n",
       "      <td>-4.642274e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177547e-15</td>\n",
       "      <td>-6.418202e-16</td>\n",
       "      <td>3.214491e-16</td>\n",
       "      <td>-1.355885e-16</td>\n",
       "      <td>-2.846052e-16</td>\n",
       "      <td>-3.028119e-16</td>\n",
       "      <td>-2.197977e-16</td>\n",
       "      <td>4.864782e-17</td>\n",
       "      <td>-0.101502</td>\n",
       "      <td>-0.216883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.247689</td>\n",
       "      <td>2.125498e-16</td>\n",
       "      <td>1.975426e-16</td>\n",
       "      <td>1.576830e-15</td>\n",
       "      <td>3.459380e-16</td>\n",
       "      <td>7.203963e-16</td>\n",
       "      <td>1.980503e-15</td>\n",
       "      <td>1.425248e-16</td>\n",
       "      <td>2.487043e-16</td>\n",
       "      <td>1.354680e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.658364e-16</td>\n",
       "      <td>7.772895e-16</td>\n",
       "      <td>-4.505332e-16</td>\n",
       "      <td>1.933267e-15</td>\n",
       "      <td>-5.600475e-16</td>\n",
       "      <td>-1.003221e-16</td>\n",
       "      <td>-2.640281e-16</td>\n",
       "      <td>-3.792314e-16</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.154876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.124348</td>\n",
       "      <td>2.053457e-16</td>\n",
       "      <td>-9.568710e-17</td>\n",
       "      <td>6.310231e-16</td>\n",
       "      <td>-5.625518e-16</td>\n",
       "      <td>7.412552e-16</td>\n",
       "      <td>2.375468e-16</td>\n",
       "      <td>-3.536655e-18</td>\n",
       "      <td>1.839891e-16</td>\n",
       "      <td>-1.079314e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.300527e-16</td>\n",
       "      <td>1.644699e-16</td>\n",
       "      <td>1.800885e-16</td>\n",
       "      <td>4.436512e-16</td>\n",
       "      <td>-5.712973e-16</td>\n",
       "      <td>-2.359969e-16</td>\n",
       "      <td>-4.672391e-16</td>\n",
       "      <td>6.415167e-16</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>-0.260593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.065902</td>\n",
       "      <td>-2.425603e-17</td>\n",
       "      <td>6.295388e-16</td>\n",
       "      <td>2.807652e-16</td>\n",
       "      <td>1.303306e-16</td>\n",
       "      <td>5.886991e-16</td>\n",
       "      <td>-1.211182e-16</td>\n",
       "      <td>1.266462e-17</td>\n",
       "      <td>-2.921856e-16</td>\n",
       "      <td>2.251072e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008461e-16</td>\n",
       "      <td>6.747721e-17</td>\n",
       "      <td>-7.132064e-16</td>\n",
       "      <td>-1.397470e-16</td>\n",
       "      <td>-5.497612e-16</td>\n",
       "      <td>-1.769255e-16</td>\n",
       "      <td>-4.720898e-16</td>\n",
       "      <td>1.144372e-15</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>-0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-0.098757</td>\n",
       "      <td>-5.020280e-16</td>\n",
       "      <td>-1.730566e-16</td>\n",
       "      <td>4.739859e-16</td>\n",
       "      <td>2.282280e-16</td>\n",
       "      <td>6.565143e-16</td>\n",
       "      <td>2.621312e-16</td>\n",
       "      <td>2.607772e-16</td>\n",
       "      <td>-8.599156e-16</td>\n",
       "      <td>3.784757e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.356561e-16</td>\n",
       "      <td>3.740383e-16</td>\n",
       "      <td>3.883204e-16</td>\n",
       "      <td>2.003482e-16</td>\n",
       "      <td>-8.547932e-16</td>\n",
       "      <td>-1.660327e-16</td>\n",
       "      <td>1.044274e-16</td>\n",
       "      <td>2.289427e-15</td>\n",
       "      <td>0.033751</td>\n",
       "      <td>-0.302544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.183453</td>\n",
       "      <td>3.547782e-16</td>\n",
       "      <td>-4.995814e-17</td>\n",
       "      <td>9.068793e-16</td>\n",
       "      <td>1.377649e-16</td>\n",
       "      <td>-8.720275e-16</td>\n",
       "      <td>-1.531188e-15</td>\n",
       "      <td>-1.690540e-16</td>\n",
       "      <td>4.127777e-16</td>\n",
       "      <td>-1.051167e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>6.605263e-17</td>\n",
       "      <td>-4.208921e-16</td>\n",
       "      <td>-3.912243e-16</td>\n",
       "      <td>-4.478263e-16</td>\n",
       "      <td>3.206423e-16</td>\n",
       "      <td>2.817791e-16</td>\n",
       "      <td>-1.143519e-15</td>\n",
       "      <td>-1.194130e-15</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.011903</td>\n",
       "      <td>7.212815e-17</td>\n",
       "      <td>1.177316e-17</td>\n",
       "      <td>8.299445e-16</td>\n",
       "      <td>-9.614528e-16</td>\n",
       "      <td>2.246261e-15</td>\n",
       "      <td>2.623672e-18</td>\n",
       "      <td>5.869302e-17</td>\n",
       "      <td>-5.254741e-16</td>\n",
       "      <td>-1.214086e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.715090e-16</td>\n",
       "      <td>-7.923387e-17</td>\n",
       "      <td>5.020770e-16</td>\n",
       "      <td>-3.005985e-16</td>\n",
       "      <td>-1.345418e-15</td>\n",
       "      <td>-7.290010e-16</td>\n",
       "      <td>6.789513e-16</td>\n",
       "      <td>7.588849e-16</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>-0.196539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-0.073297</td>\n",
       "      <td>-3.879840e-16</td>\n",
       "      <td>-2.685296e-16</td>\n",
       "      <td>7.614712e-16</td>\n",
       "      <td>-2.699612e-16</td>\n",
       "      <td>1.281914e-16</td>\n",
       "      <td>2.015618e-16</td>\n",
       "      <td>2.177192e-16</td>\n",
       "      <td>-2.269549e-16</td>\n",
       "      <td>1.113695e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.230527e-16</td>\n",
       "      <td>-8.743398e-16</td>\n",
       "      <td>3.706214e-16</td>\n",
       "      <td>-2.403828e-16</td>\n",
       "      <td>2.666806e-16</td>\n",
       "      <td>6.932833e-16</td>\n",
       "      <td>6.148525e-16</td>\n",
       "      <td>-5.534540e-17</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>-0.326481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.090438</td>\n",
       "      <td>3.230206e-17</td>\n",
       "      <td>3.284605e-16</td>\n",
       "      <td>1.509897e-16</td>\n",
       "      <td>-5.103644e-16</td>\n",
       "      <td>5.308590e-16</td>\n",
       "      <td>1.223814e-16</td>\n",
       "      <td>7.604126e-17</td>\n",
       "      <td>-3.667974e-16</td>\n",
       "      <td>4.993240e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.408680e-16</td>\n",
       "      <td>-4.819365e-16</td>\n",
       "      <td>-1.912006e-16</td>\n",
       "      <td>-8.986916e-17</td>\n",
       "      <td>-6.629212e-17</td>\n",
       "      <td>2.990167e-16</td>\n",
       "      <td>2.242791e-16</td>\n",
       "      <td>7.976796e-16</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>-0.111485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.028975</td>\n",
       "      <td>1.502024e-16</td>\n",
       "      <td>-7.118719e-18</td>\n",
       "      <td>3.463522e-16</td>\n",
       "      <td>-3.980557e-16</td>\n",
       "      <td>-1.450421e-16</td>\n",
       "      <td>-1.865597e-16</td>\n",
       "      <td>-1.881008e-16</td>\n",
       "      <td>-3.875186e-16</td>\n",
       "      <td>-1.376135e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>5.115885e-16</td>\n",
       "      <td>-1.163768e-15</td>\n",
       "      <td>7.032035e-16</td>\n",
       "      <td>2.587708e-17</td>\n",
       "      <td>9.577163e-16</td>\n",
       "      <td>5.898033e-16</td>\n",
       "      <td>-2.959370e-16</td>\n",
       "      <td>-1.405379e-15</td>\n",
       "      <td>-0.056151</td>\n",
       "      <td>0.034783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.050866</td>\n",
       "      <td>4.654551e-16</td>\n",
       "      <td>2.506675e-16</td>\n",
       "      <td>-9.316409e-16</td>\n",
       "      <td>-1.857247e-16</td>\n",
       "      <td>-3.554057e-16</td>\n",
       "      <td>-1.858755e-16</td>\n",
       "      <td>9.379684e-16</td>\n",
       "      <td>2.033737e-16</td>\n",
       "      <td>-2.343720e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.614597e-16</td>\n",
       "      <td>1.009285e-15</td>\n",
       "      <td>2.712885e-16</td>\n",
       "      <td>1.277215e-16</td>\n",
       "      <td>1.410054e-16</td>\n",
       "      <td>-2.803504e-16</td>\n",
       "      <td>-1.138829e-15</td>\n",
       "      <td>-2.436795e-16</td>\n",
       "      <td>0.339403</td>\n",
       "      <td>0.020090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.044736</td>\n",
       "      <td>-2.457409e-16</td>\n",
       "      <td>-8.480447e-17</td>\n",
       "      <td>5.706192e-17</td>\n",
       "      <td>-1.949553e-16</td>\n",
       "      <td>-3.920976e-16</td>\n",
       "      <td>5.833316e-17</td>\n",
       "      <td>-2.027779e-16</td>\n",
       "      <td>3.892798e-16</td>\n",
       "      <td>1.936953e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.649908e-15</td>\n",
       "      <td>8.119580e-16</td>\n",
       "      <td>1.761054e-16</td>\n",
       "      <td>-1.686082e-16</td>\n",
       "      <td>-5.557329e-16</td>\n",
       "      <td>-1.211281e-15</td>\n",
       "      <td>5.278775e-16</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.144059</td>\n",
       "      <td>-4.290944e-16</td>\n",
       "      <td>1.526333e-16</td>\n",
       "      <td>-1.133902e-15</td>\n",
       "      <td>-6.276051e-17</td>\n",
       "      <td>1.253751e-16</td>\n",
       "      <td>-4.705235e-19</td>\n",
       "      <td>-8.898922e-16</td>\n",
       "      <td>2.026927e-16</td>\n",
       "      <td>-7.071869e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.649908e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.303916e-17</td>\n",
       "      <td>9.970809e-17</td>\n",
       "      <td>-5.018575e-16</td>\n",
       "      <td>-2.503187e-17</td>\n",
       "      <td>8.461337e-17</td>\n",
       "      <td>-6.627203e-16</td>\n",
       "      <td>-0.064801</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.051142</td>\n",
       "      <td>6.168652e-16</td>\n",
       "      <td>1.634231e-16</td>\n",
       "      <td>-4.983035e-16</td>\n",
       "      <td>9.164206e-17</td>\n",
       "      <td>-8.428683e-18</td>\n",
       "      <td>1.046712e-16</td>\n",
       "      <td>-4.387401e-16</td>\n",
       "      <td>6.377260e-17</td>\n",
       "      <td>-5.214137e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.119580e-16</td>\n",
       "      <td>-7.303916e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.130519e-17</td>\n",
       "      <td>-8.232727e-17</td>\n",
       "      <td>1.114524e-15</td>\n",
       "      <td>2.839721e-16</td>\n",
       "      <td>1.481903e-15</td>\n",
       "      <td>-0.112633</td>\n",
       "      <td>-0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.016182</td>\n",
       "      <td>-4.425156e-17</td>\n",
       "      <td>1.247925e-17</td>\n",
       "      <td>2.686834e-19</td>\n",
       "      <td>1.584638e-16</td>\n",
       "      <td>-1.149255e-15</td>\n",
       "      <td>-1.071589e-15</td>\n",
       "      <td>7.434913e-18</td>\n",
       "      <td>-1.047097e-16</td>\n",
       "      <td>-1.430343e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.761054e-16</td>\n",
       "      <td>9.970809e-17</td>\n",
       "      <td>2.130519e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.015391e-15</td>\n",
       "      <td>1.343722e-16</td>\n",
       "      <td>-2.274142e-16</td>\n",
       "      <td>-2.819805e-16</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>-0.007221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-0.233083</td>\n",
       "      <td>-9.605737e-16</td>\n",
       "      <td>-4.478846e-16</td>\n",
       "      <td>-1.104734e-15</td>\n",
       "      <td>6.070716e-16</td>\n",
       "      <td>4.808532e-16</td>\n",
       "      <td>4.562861e-16</td>\n",
       "      <td>-3.094082e-16</td>\n",
       "      <td>-4.653279e-16</td>\n",
       "      <td>6.757763e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.686082e-16</td>\n",
       "      <td>-5.018575e-16</td>\n",
       "      <td>-8.232727e-17</td>\n",
       "      <td>1.015391e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.646517e-15</td>\n",
       "      <td>-6.406679e-16</td>\n",
       "      <td>-7.008939e-16</td>\n",
       "      <td>-0.047837</td>\n",
       "      <td>0.003308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.041407</td>\n",
       "      <td>-1.581290e-17</td>\n",
       "      <td>2.057310e-16</td>\n",
       "      <td>-1.238062e-16</td>\n",
       "      <td>-4.247268e-16</td>\n",
       "      <td>4.319541e-16</td>\n",
       "      <td>-1.357067e-16</td>\n",
       "      <td>-9.657637e-16</td>\n",
       "      <td>-1.727276e-16</td>\n",
       "      <td>-7.888853e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.557329e-16</td>\n",
       "      <td>-2.503187e-17</td>\n",
       "      <td>1.114524e-15</td>\n",
       "      <td>1.343722e-16</td>\n",
       "      <td>2.646517e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.667715e-16</td>\n",
       "      <td>-2.782204e-16</td>\n",
       "      <td>-0.003208</td>\n",
       "      <td>0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.005135</td>\n",
       "      <td>1.198124e-16</td>\n",
       "      <td>-4.966953e-16</td>\n",
       "      <td>1.045747e-15</td>\n",
       "      <td>3.977061e-17</td>\n",
       "      <td>6.590482e-16</td>\n",
       "      <td>-4.452461e-16</td>\n",
       "      <td>-1.782106e-15</td>\n",
       "      <td>1.299943e-16</td>\n",
       "      <td>-6.709655e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.211281e-15</td>\n",
       "      <td>8.461337e-17</td>\n",
       "      <td>2.839721e-16</td>\n",
       "      <td>-2.274142e-16</td>\n",
       "      <td>-6.406679e-16</td>\n",
       "      <td>-3.667715e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.061287e-16</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.017580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.009413</td>\n",
       "      <td>2.083082e-15</td>\n",
       "      <td>-5.093836e-16</td>\n",
       "      <td>9.775546e-16</td>\n",
       "      <td>-2.761403e-18</td>\n",
       "      <td>-5.613951e-18</td>\n",
       "      <td>2.594754e-16</td>\n",
       "      <td>-2.776530e-16</td>\n",
       "      <td>-6.200930e-16</td>\n",
       "      <td>1.110541e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>5.278775e-16</td>\n",
       "      <td>-6.627203e-16</td>\n",
       "      <td>1.481903e-15</td>\n",
       "      <td>-2.819805e-16</td>\n",
       "      <td>-7.008939e-16</td>\n",
       "      <td>-2.782204e-16</td>\n",
       "      <td>-3.061287e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.009536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-0.010596</td>\n",
       "      <td>-2.277087e-01</td>\n",
       "      <td>-5.314089e-01</td>\n",
       "      <td>-2.108805e-01</td>\n",
       "      <td>9.873167e-02</td>\n",
       "      <td>-3.863563e-01</td>\n",
       "      <td>2.159812e-01</td>\n",
       "      <td>3.973113e-01</td>\n",
       "      <td>-1.030791e-01</td>\n",
       "      <td>-4.424560e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059989e-01</td>\n",
       "      <td>-6.480065e-02</td>\n",
       "      <td>-1.126326e-01</td>\n",
       "      <td>5.146217e-03</td>\n",
       "      <td>-4.783686e-02</td>\n",
       "      <td>-3.208037e-03</td>\n",
       "      <td>2.882546e-02</td>\n",
       "      <td>1.025822e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>-0.012323</td>\n",
       "      <td>-1.013473e-01</td>\n",
       "      <td>9.128865e-02</td>\n",
       "      <td>-1.929608e-01</td>\n",
       "      <td>1.334475e-01</td>\n",
       "      <td>-9.497430e-02</td>\n",
       "      <td>-4.364316e-02</td>\n",
       "      <td>-1.872566e-01</td>\n",
       "      <td>1.987512e-02</td>\n",
       "      <td>-9.773269e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.041338e-02</td>\n",
       "      <td>8.053175e-04</td>\n",
       "      <td>-2.685156e-03</td>\n",
       "      <td>-7.220907e-03</td>\n",
       "      <td>3.307706e-03</td>\n",
       "      <td>4.455398e-03</td>\n",
       "      <td>1.757973e-02</td>\n",
       "      <td>9.536041e-03</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time            V1            V2            V3            V4  \\\n",
       "Time    1.000000  1.173963e-01 -1.059333e-02 -4.196182e-01 -1.052602e-01   \n",
       "V1      0.117396  1.000000e+00  4.135835e-16 -1.227819e-15 -9.215150e-16   \n",
       "V2     -0.010593  4.135835e-16  1.000000e+00  3.243764e-16 -1.121065e-15   \n",
       "V3     -0.419618 -1.227819e-15  3.243764e-16  1.000000e+00  4.711293e-16   \n",
       "V4     -0.105260 -9.215150e-16 -1.121065e-15  4.711293e-16  1.000000e+00   \n",
       "V5      0.173072  1.812612e-17  5.157519e-16 -6.539009e-17 -1.719944e-15   \n",
       "V6     -0.063016 -6.506567e-16  2.787346e-16  1.627627e-15 -7.491959e-16   \n",
       "V7      0.084714 -1.005191e-15  2.055934e-16  4.895305e-16 -4.104503e-16   \n",
       "V8     -0.036949 -2.433822e-16 -5.377041e-17 -1.268779e-15  5.697192e-16   \n",
       "V9     -0.008660 -1.513678e-16  1.978488e-17  5.568367e-16  6.923247e-16   \n",
       "V10     0.030617  7.388135e-17 -3.991394e-16  1.156587e-15  2.232685e-16   \n",
       "V11    -0.247689  2.125498e-16  1.975426e-16  1.576830e-15  3.459380e-16   \n",
       "V12     0.124348  2.053457e-16 -9.568710e-17  6.310231e-16 -5.625518e-16   \n",
       "V13    -0.065902 -2.425603e-17  6.295388e-16  2.807652e-16  1.303306e-16   \n",
       "V14    -0.098757 -5.020280e-16 -1.730566e-16  4.739859e-16  2.282280e-16   \n",
       "V15    -0.183453  3.547782e-16 -4.995814e-17  9.068793e-16  1.377649e-16   \n",
       "V16     0.011903  7.212815e-17  1.177316e-17  8.299445e-16 -9.614528e-16   \n",
       "V17    -0.073297 -3.879840e-16 -2.685296e-16  7.614712e-16 -2.699612e-16   \n",
       "V18     0.090438  3.230206e-17  3.284605e-16  1.509897e-16 -5.103644e-16   \n",
       "V19     0.028975  1.502024e-16 -7.118719e-18  3.463522e-16 -3.980557e-16   \n",
       "V20    -0.050866  4.654551e-16  2.506675e-16 -9.316409e-16 -1.857247e-16   \n",
       "V21     0.044736 -2.457409e-16 -8.480447e-17  5.706192e-17 -1.949553e-16   \n",
       "V22     0.144059 -4.290944e-16  1.526333e-16 -1.133902e-15 -6.276051e-17   \n",
       "V23     0.051142  6.168652e-16  1.634231e-16 -4.983035e-16  9.164206e-17   \n",
       "V24    -0.016182 -4.425156e-17  1.247925e-17  2.686834e-19  1.584638e-16   \n",
       "V25    -0.233083 -9.605737e-16 -4.478846e-16 -1.104734e-15  6.070716e-16   \n",
       "V26    -0.041407 -1.581290e-17  2.057310e-16 -1.238062e-16 -4.247268e-16   \n",
       "V27    -0.005135  1.198124e-16 -4.966953e-16  1.045747e-15  3.977061e-17   \n",
       "V28    -0.009413  2.083082e-15 -5.093836e-16  9.775546e-16 -2.761403e-18   \n",
       "Amount -0.010596 -2.277087e-01 -5.314089e-01 -2.108805e-01  9.873167e-02   \n",
       "Class  -0.012323 -1.013473e-01  9.128865e-02 -1.929608e-01  1.334475e-01   \n",
       "\n",
       "                  V5            V6            V7            V8            V9  \\\n",
       "Time    1.730721e-01 -6.301647e-02  8.471437e-02 -3.694943e-02 -8.660434e-03   \n",
       "V1      1.812612e-17 -6.506567e-16 -1.005191e-15 -2.433822e-16 -1.513678e-16   \n",
       "V2      5.157519e-16  2.787346e-16  2.055934e-16 -5.377041e-17  1.978488e-17   \n",
       "V3     -6.539009e-17  1.627627e-15  4.895305e-16 -1.268779e-15  5.568367e-16   \n",
       "V4     -1.719944e-15 -7.491959e-16 -4.104503e-16  5.697192e-16  6.923247e-16   \n",
       "V5      1.000000e+00  2.408382e-16  2.715541e-16  7.437229e-16  7.391702e-16   \n",
       "V6      2.408382e-16  1.000000e+00  1.191668e-16 -1.104219e-16  4.131207e-16   \n",
       "V7      2.715541e-16  1.191668e-16  1.000000e+00  3.344412e-16  1.122501e-15   \n",
       "V8      7.437229e-16 -1.104219e-16  3.344412e-16  1.000000e+00  4.356078e-16   \n",
       "V9      7.391702e-16  4.131207e-16  1.122501e-15  4.356078e-16  1.000000e+00   \n",
       "V10    -5.202306e-16  5.932243e-17 -7.492834e-17 -2.801370e-16 -4.642274e-16   \n",
       "V11     7.203963e-16  1.980503e-15  1.425248e-16  2.487043e-16  1.354680e-16   \n",
       "V12     7.412552e-16  2.375468e-16 -3.536655e-18  1.839891e-16 -1.079314e-15   \n",
       "V13     5.886991e-16 -1.211182e-16  1.266462e-17 -2.921856e-16  2.251072e-15   \n",
       "V14     6.565143e-16  2.621312e-16  2.607772e-16 -8.599156e-16  3.784757e-15   \n",
       "V15    -8.720275e-16 -1.531188e-15 -1.690540e-16  4.127777e-16 -1.051167e-15   \n",
       "V16     2.246261e-15  2.623672e-18  5.869302e-17 -5.254741e-16 -1.214086e-15   \n",
       "V17     1.281914e-16  2.015618e-16  2.177192e-16 -2.269549e-16  1.113695e-15   \n",
       "V18     5.308590e-16  1.223814e-16  7.604126e-17 -3.667974e-16  4.993240e-16   \n",
       "V19    -1.450421e-16 -1.865597e-16 -1.881008e-16 -3.875186e-16 -1.376135e-16   \n",
       "V20    -3.554057e-16 -1.858755e-16  9.379684e-16  2.033737e-16 -2.343720e-16   \n",
       "V21    -3.920976e-16  5.833316e-17 -2.027779e-16  3.892798e-16  1.936953e-16   \n",
       "V22     1.253751e-16 -4.705235e-19 -8.898922e-16  2.026927e-16 -7.071869e-16   \n",
       "V23    -8.428683e-18  1.046712e-16 -4.387401e-16  6.377260e-17 -5.214137e-16   \n",
       "V24    -1.149255e-15 -1.071589e-15  7.434913e-18 -1.047097e-16 -1.430343e-16   \n",
       "V25     4.808532e-16  4.562861e-16 -3.094082e-16 -4.653279e-16  6.757763e-16   \n",
       "V26     4.319541e-16 -1.357067e-16 -9.657637e-16 -1.727276e-16 -7.888853e-16   \n",
       "V27     6.590482e-16 -4.452461e-16 -1.782106e-15  1.299943e-16 -6.709655e-17   \n",
       "V28    -5.613951e-18  2.594754e-16 -2.776530e-16 -6.200930e-16  1.110541e-15   \n",
       "Amount -3.863563e-01  2.159812e-01  3.973113e-01 -1.030791e-01 -4.424560e-02   \n",
       "Class  -9.497430e-02 -4.364316e-02 -1.872566e-01  1.987512e-02 -9.773269e-02   \n",
       "\n",
       "        ...           V21           V22           V23           V24  \\\n",
       "Time    ...  4.473573e-02  1.440591e-01  5.114236e-02 -1.618187e-02   \n",
       "V1      ... -2.457409e-16 -4.290944e-16  6.168652e-16 -4.425156e-17   \n",
       "V2      ... -8.480447e-17  1.526333e-16  1.634231e-16  1.247925e-17   \n",
       "V3      ...  5.706192e-17 -1.133902e-15 -4.983035e-16  2.686834e-19   \n",
       "V4      ... -1.949553e-16 -6.276051e-17  9.164206e-17  1.584638e-16   \n",
       "V5      ... -3.920976e-16  1.253751e-16 -8.428683e-18 -1.149255e-15   \n",
       "V6      ...  5.833316e-17 -4.705235e-19  1.046712e-16 -1.071589e-15   \n",
       "V7      ... -2.027779e-16 -8.898922e-16 -4.387401e-16  7.434913e-18   \n",
       "V8      ...  3.892798e-16  2.026927e-16  6.377260e-17 -1.047097e-16   \n",
       "V9      ...  1.936953e-16 -7.071869e-16 -5.214137e-16 -1.430343e-16   \n",
       "V10     ...  1.177547e-15 -6.418202e-16  3.214491e-16 -1.355885e-16   \n",
       "V11     ... -5.658364e-16  7.772895e-16 -4.505332e-16  1.933267e-15   \n",
       "V12     ...  7.300527e-16  1.644699e-16  1.800885e-16  4.436512e-16   \n",
       "V13     ...  1.008461e-16  6.747721e-17 -7.132064e-16 -1.397470e-16   \n",
       "V14     ... -3.356561e-16  3.740383e-16  3.883204e-16  2.003482e-16   \n",
       "V15     ...  6.605263e-17 -4.208921e-16 -3.912243e-16 -4.478263e-16   \n",
       "V16     ... -4.715090e-16 -7.923387e-17  5.020770e-16 -3.005985e-16   \n",
       "V17     ... -8.230527e-16 -8.743398e-16  3.706214e-16 -2.403828e-16   \n",
       "V18     ... -9.408680e-16 -4.819365e-16 -1.912006e-16 -8.986916e-17   \n",
       "V19     ...  5.115885e-16 -1.163768e-15  7.032035e-16  2.587708e-17   \n",
       "V20     ... -7.614597e-16  1.009285e-15  2.712885e-16  1.277215e-16   \n",
       "V21     ...  1.000000e+00  3.649908e-15  8.119580e-16  1.761054e-16   \n",
       "V22     ...  3.649908e-15  1.000000e+00 -7.303916e-17  9.970809e-17   \n",
       "V23     ...  8.119580e-16 -7.303916e-17  1.000000e+00  2.130519e-17   \n",
       "V24     ...  1.761054e-16  9.970809e-17  2.130519e-17  1.000000e+00   \n",
       "V25     ... -1.686082e-16 -5.018575e-16 -8.232727e-17  1.015391e-15   \n",
       "V26     ... -5.557329e-16 -2.503187e-17  1.114524e-15  1.343722e-16   \n",
       "V27     ... -1.211281e-15  8.461337e-17  2.839721e-16 -2.274142e-16   \n",
       "V28     ...  5.278775e-16 -6.627203e-16  1.481903e-15 -2.819805e-16   \n",
       "Amount  ...  1.059989e-01 -6.480065e-02 -1.126326e-01  5.146217e-03   \n",
       "Class   ...  4.041338e-02  8.053175e-04 -2.685156e-03 -7.220907e-03   \n",
       "\n",
       "                 V25           V26           V27           V28    Amount  \\\n",
       "Time   -2.330828e-01 -4.140710e-02 -5.134591e-03 -9.412688e-03 -0.010596   \n",
       "V1     -9.605737e-16 -1.581290e-17  1.198124e-16  2.083082e-15 -0.227709   \n",
       "V2     -4.478846e-16  2.057310e-16 -4.966953e-16 -5.093836e-16 -0.531409   \n",
       "V3     -1.104734e-15 -1.238062e-16  1.045747e-15  9.775546e-16 -0.210880   \n",
       "V4      6.070716e-16 -4.247268e-16  3.977061e-17 -2.761403e-18  0.098732   \n",
       "V5      4.808532e-16  4.319541e-16  6.590482e-16 -5.613951e-18 -0.386356   \n",
       "V6      4.562861e-16 -1.357067e-16 -4.452461e-16  2.594754e-16  0.215981   \n",
       "V7     -3.094082e-16 -9.657637e-16 -1.782106e-15 -2.776530e-16  0.397311   \n",
       "V8     -4.653279e-16 -1.727276e-16  1.299943e-16 -6.200930e-16 -0.103079   \n",
       "V9      6.757763e-16 -7.888853e-16 -6.709655e-17  1.110541e-15 -0.044246   \n",
       "V10    -2.846052e-16 -3.028119e-16 -2.197977e-16  4.864782e-17 -0.101502   \n",
       "V11    -5.600475e-16 -1.003221e-16 -2.640281e-16 -3.792314e-16  0.000104   \n",
       "V12    -5.712973e-16 -2.359969e-16 -4.672391e-16  6.415167e-16 -0.009542   \n",
       "V13    -5.497612e-16 -1.769255e-16 -4.720898e-16  1.144372e-15  0.005293   \n",
       "V14    -8.547932e-16 -1.660327e-16  1.044274e-16  2.289427e-15  0.033751   \n",
       "V15     3.206423e-16  2.817791e-16 -1.143519e-15 -1.194130e-15 -0.002986   \n",
       "V16    -1.345418e-15 -7.290010e-16  6.789513e-16  7.588849e-16 -0.003910   \n",
       "V17     2.666806e-16  6.932833e-16  6.148525e-16 -5.534540e-17  0.007309   \n",
       "V18    -6.629212e-17  2.990167e-16  2.242791e-16  7.976796e-16  0.035650   \n",
       "V19     9.577163e-16  5.898033e-16 -2.959370e-16 -1.405379e-15 -0.056151   \n",
       "V20     1.410054e-16 -2.803504e-16 -1.138829e-15 -2.436795e-16  0.339403   \n",
       "V21    -1.686082e-16 -5.557329e-16 -1.211281e-15  5.278775e-16  0.105999   \n",
       "V22    -5.018575e-16 -2.503187e-17  8.461337e-17 -6.627203e-16 -0.064801   \n",
       "V23    -8.232727e-17  1.114524e-15  2.839721e-16  1.481903e-15 -0.112633   \n",
       "V24     1.015391e-15  1.343722e-16 -2.274142e-16 -2.819805e-16  0.005146   \n",
       "V25     1.000000e+00  2.646517e-15 -6.406679e-16 -7.008939e-16 -0.047837   \n",
       "V26     2.646517e-15  1.000000e+00 -3.667715e-16 -2.782204e-16 -0.003208   \n",
       "V27    -6.406679e-16 -3.667715e-16  1.000000e+00 -3.061287e-16  0.028825   \n",
       "V28    -7.008939e-16 -2.782204e-16 -3.061287e-16  1.000000e+00  0.010258   \n",
       "Amount -4.783686e-02 -3.208037e-03  2.882546e-02  1.025822e-02  1.000000   \n",
       "Class   3.307706e-03  4.455398e-03  1.757973e-02  9.536041e-03  0.005632   \n",
       "\n",
       "           Class  \n",
       "Time   -0.012323  \n",
       "V1     -0.101347  \n",
       "V2      0.091289  \n",
       "V3     -0.192961  \n",
       "V4      0.133447  \n",
       "V5     -0.094974  \n",
       "V6     -0.043643  \n",
       "V7     -0.187257  \n",
       "V8      0.019875  \n",
       "V9     -0.097733  \n",
       "V10    -0.216883  \n",
       "V11     0.154876  \n",
       "V12    -0.260593  \n",
       "V13    -0.004570  \n",
       "V14    -0.302544  \n",
       "V15    -0.004223  \n",
       "V16    -0.196539  \n",
       "V17    -0.326481  \n",
       "V18    -0.111485  \n",
       "V19     0.034783  \n",
       "V20     0.020090  \n",
       "V21     0.040413  \n",
       "V22     0.000805  \n",
       "V23    -0.002685  \n",
       "V24    -0.007221  \n",
       "V25     0.003308  \n",
       "V26     0.004455  \n",
       "V27     0.017580  \n",
       "V28     0.009536  \n",
       "Amount  0.005632  \n",
       "Class   1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation matrix\n",
    "corr= df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d3bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Split\n",
    "X = df.drop(columns=['Class'], axis=1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234a0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_scaler= sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ffeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train ,X_test, Y_train, Y_test = train_test_split(X_scaler, Y, test_size=0.25, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7211ca6",
   "metadata": {},
   "source": [
    "## Implementing models without Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eeb6126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.84      0.62      0.71       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.92      0.81      0.85     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.7102803738317757\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg= LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred_lr = logreg.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_lr))\n",
    "print(f1_score(Y_test, Y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a7da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import compute_class_weight\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb643058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights :  ({0: 0.5008652385150725, 1: 289.43766937669375},)\n"
     ]
    }
   ],
   "source": [
    "train_classes = Y_train\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_classes),\n",
    "                                        y = train_classes                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(train_classes), class_weights)),\n",
    "print(\"class_weights : \", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b5214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(X.columns))\n",
    "n_inputs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6861f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0168 - val_loss: 0.0034\n",
      "Epoch 2/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 3/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 4/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 5/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 6/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 7/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 8/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 9/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 10/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 11/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 12/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 13/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 14/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 16/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 8.4058e-04 - val_loss: 0.0023\n",
      "Epoch 17/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 18/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 19/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 8.6131e-04 - val_loss: 0.0029\n",
      "Epoch 20/20\n",
      "\u001b[1m6008/6008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 9.6266e-04 - val_loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e202f76e60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural network model\n",
    "model= Sequential()\n",
    "model.add(Dense(64, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam')\n",
    "class_weights = {0: 0.5, 1: 289}\n",
    "model.fit(X_train, Y_train, validation_split = 0.1,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea04b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 901us/step\n",
      "0.9559485340769922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "Y_pred_nn= model.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(Y_test,Y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aa599b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.71      0.68      0.70       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.86      0.84      0.85     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.6970954356846473\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dectree = DecisionTreeClassifier()\n",
    "dectree.fit(X_train, Y_train)\n",
    "Y_pred_dt= dectree.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_dt))\n",
    "print(f1_score(Y_test, Y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f3e7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.95      0.76      0.85       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.97      0.88      0.92     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.8468468468468469\n"
     ]
    }
   ],
   "source": [
    "#Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfor = RandomForestClassifier()\n",
    "randfor.fit(X_train, Y_train)\n",
    "Y_pred_rf= randfor.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_rf))\n",
    "print(f1_score(Y_test, Y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6b309e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.69      0.18      0.28       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.84      0.59      0.64     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.2838709677419355\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradbst = GradientBoostingClassifier()\n",
    "gradbst.fit(X_train, Y_train)\n",
    "Y_pred_gb= gradbst.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_gb))\n",
    "print(f1_score(Y_test, Y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2795f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.95      0.79      0.86       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.98      0.89      0.93     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.8622222222222222\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST model\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, Y_train)\n",
    "Y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_xgb))\n",
    "print(f1_score(Y_test, Y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a83537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 369, number of negative: 213236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 213605, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001727 -> initscore=-6.359358\n",
      "[LightGBM] [Info] Start training from score -6.359358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.38      0.62      0.47       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.69      0.81      0.73     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.4691358024691358\n"
     ]
    }
   ],
   "source": [
    "#Lightgbm model\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, Y_train)\n",
    "Y_pred_lgbm = lgbm.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_lgbm))\n",
    "print(f1_score(Y_test, Y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ae85d",
   "metadata": {},
   "source": [
    "## Using smote to balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d4781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "over_sample = SMOTE()\n",
    "x_smote, y_smote = over_sample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d41dbcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71079\n",
      "           1       0.06      0.89      0.11       123\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.53      0.93      0.55     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n",
      "0.11077235772357724\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg= LogisticRegression(random_state=42)\n",
    "logreg.fit(x_smote, y_smote)\n",
    "Y_pred_lrs = logreg.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_lrs))\n",
    "print(f1_score(Y_test, Y_pred_lrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb6118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.9845 - loss: 0.0447 - val_accuracy: 0.9999 - val_loss: 0.0030\n",
      "Epoch 2/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 7.6224e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 4.3907e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 6.1072e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 2.5547e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 5.5628e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 3.6157e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.3953e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9952 - val_loss: 0.0174\n",
      "Epoch 11/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 5.6695e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 1.0135e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.3470e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 6.4283e-04 - val_accuracy: 1.0000 - val_loss: 8.9016e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 7.2641e-04 - val_accuracy: 0.9989 - val_loss: 0.0038\n",
      "Epoch 16/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 5.5428e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 9.6408e-04 - val_accuracy: 1.0000 - val_loss: 3.6024e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 7.7047e-04 - val_accuracy: 1.0000 - val_loss: 7.1433e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 9.0390e-04 - val_accuracy: 1.0000 - val_loss: 8.6657e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m11995/11995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 5.4158e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e203b13f10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "n_inputs=30\n",
    "\n",
    "#Neural network model\n",
    "model= Sequential()\n",
    "model.add(Dense(64,input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics= ['accuracy'])\n",
    "model.fit(x_smote, y_smote, validation_split = 0.1,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fd28eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 856us/step\n",
      "0.9507106886795033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "Y_pred_nns= model.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(Y_test,Y_pred_nns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f65f382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.36      0.73      0.48       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.68      0.86      0.74     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.48257372654155495\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dectree = DecisionTreeClassifier()\n",
    "dectree.fit(x_smote, y_smote)\n",
    "Y_pred_dts= dectree.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_dts))\n",
    "print(f1_score(Y_test, Y_pred_dts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02a433f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.86      0.78      0.82       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.93      0.89      0.91     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.8170212765957446\n"
     ]
    }
   ],
   "source": [
    "#Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfor = RandomForestClassifier()\n",
    "randfor.fit(x_smote, y_smote)\n",
    "Y_pred_rfs= randfor.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_rfs))\n",
    "print(f1_score(Y_test, Y_pred_rfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "590e9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     71079\n",
      "           1       0.11      0.89      0.20       123\n",
      "\n",
      "    accuracy                           0.99     71202\n",
      "   macro avg       0.56      0.94      0.60     71202\n",
      "weighted avg       1.00      0.99      0.99     71202\n",
      "\n",
      "0.19963369963369965\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradbst = GradientBoostingClassifier()\n",
    "gradbst.fit(x_smote, y_smote)\n",
    "Y_pred_gbs= gradbst.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_gbs))\n",
    "print(f1_score(Y_test, Y_pred_gbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6c2cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.72      0.83      0.77       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.86      0.91      0.89     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST model\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_smote, y_smote)\n",
    "Y_pred_xgbs = xgb.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_xgbs))\n",
    "print(f1_score(Y_test, Y_pred_xgbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adc4cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 213236, number of negative: 213236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 426472, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.54      0.85      0.66       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.77      0.93      0.83     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "0.6645569620253164\n"
     ]
    }
   ],
   "source": [
    "#Lightgbm model\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(x_smote, y_smote)\n",
    "Y_pred_lgbms = lgbm.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_lgbms))\n",
    "print(f1_score(Y_test, Y_pred_lgbms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7996c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "import joblib\n",
    "filename= 'savemodel.sav'\n",
    "joblib.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "007064fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16129942, -3.03021342,  2.99919313,  0.07905034, -1.53525328,\n",
       "        0.19846265, -0.40149543,  2.00992122, -1.6265321 ,  6.08361467,\n",
       "       10.24926823,  2.41894826, -0.79659111, -1.41527106, -3.96600162,\n",
       "        1.16572379, -1.10864988, -2.47714223, -0.4558958 , -0.48564479,\n",
       "        5.86586128, -2.26341289, -1.35058232, -0.22384469, -0.27800346,\n",
       "        1.92224883, -0.21774797,  3.49120892, -1.08560132, -0.31744652])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b90265fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model= joblib.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd0d1e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'load_model' is your trained model\n",
    "input_data = [[-1.16129942, -3.03021342,  2.99919313,  0.07905034, -1.53525328,\n",
    "        0.19846265, -0.40149543,  2.00992122, -1.6265321 ,  6.08361467,\n",
    "       10.24926823,  2.41894826, -0.79659111, -1.41527106, -3.96600162,\n",
    "        1.16572379, -1.10864988, -2.47714223, -0.4558958 , -0.48564479,\n",
    "        5.86586128, -2.26341289, -1.35058232, -0.22384469, -0.27800346,\n",
    "        1.92224883, -0.21774797,  3.49120892, -1.08560132, -0.31744652]]\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "input_data_array = np.array(input_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = load_model.predict(input_data_array)\n",
    "\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2229f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
